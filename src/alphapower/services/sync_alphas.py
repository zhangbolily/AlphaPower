import asyncio
import gc
import signal
import types
from datetime import datetime, timedelta
from typing import List, Optional, Tuple

from structlog.stdlib import BoundLogger

from alphapower.client import (
    WorldQuantClient,
    wq_client,
)
from alphapower.constants import (
    MAX_COUNT_IN_SINGLE_ALPHA_LIST_QUERY,
    Color,
    Database,
    Grade,
    Status,
)
from alphapower.dal.alphas import (
    AlphaDAL,
)
from alphapower.dal.base import DALFactory
from alphapower.entity import (
    Alpha,
)
from alphapower.internal.db_session import get_db_session
from alphapower.internal.logging import get_logger
from alphapower.view.alpha import (
    AlphaView,
    SelfAlphaListQueryParams,
    SelfAlphaListView,
)

from .sync_competition import competition_data_expire_check, sync_competition
from .utils import create_aggregate_data


class AlphaSyncService:

    def __init__(self) -> None:

        self.log: BoundLogger = get_logger(__name__)
        self.exit_event: asyncio.Event = asyncio.Event()
        self._db_lock: asyncio.Lock = asyncio.Lock()

    def setup_exit_signal_handler(self) -> None:

        def handle_exit_signal(signum: int, _: Optional[types.FrameType]) -> None:
            self.log.warning(
                "æ¥æ”¶åˆ°é€€å‡ºä¿¡å·ï¼Œå‡†å¤‡ç»ˆæ­¢æ“ä½œ",
                signal=signum,
                module=__name__,
                emoji="ğŸ›‘",
            )
            # è®¾ç½®é€€å‡ºäº‹ä»¶ï¼Œé€šçŸ¥æ‰€æœ‰åç¨‹åœæ­¢æ“ä½œ
            self.exit_event.set()

        signal.signal(signal.SIGINT, handle_exit_signal)  # å¤„ç† Ctrl+C
        signal.signal(signal.SIGTERM, handle_exit_signal)  # å¤„ç†ç»ˆæ­¢ä¿¡å·

    def create_alpha(
        self,
        alpha_view: AlphaView,
    ) -> Alpha:

        try:
            alpha: Alpha = Alpha(
                alpha_id=alpha_view.id,
                type=alpha_view.type,
                author=alpha_view.author,
                settings=alpha_view.settings,
                regular=alpha_view.regular,
                combo=alpha_view.combo,
                selection=alpha_view.selection,
                date_created=alpha_view.date_created,
                date_submitted=alpha_view.date_submitted,
                date_modified=alpha_view.date_modified,
                name=alpha_view.name,
                favorite=alpha_view.favorite,
                hidden=alpha_view.hidden,
                color=alpha_view.color if alpha_view.color else Color.NONE,
                category=alpha_view.category,
                tags=alpha_view.tags,
                grade=alpha_view.grade if alpha_view.grade else Grade.DEFAULT,
                stage=alpha_view.stage,
                status=alpha_view.status,
                in_sample=create_aggregate_data(alpha_view.in_sample),
                out_sample=create_aggregate_data(alpha_view.out_sample),
                train=create_aggregate_data(alpha_view.train),
                test=create_aggregate_data(alpha_view.test),
                prod=create_aggregate_data(alpha_view.prod),
                pyramids=alpha_view.pyramids,
                competitions=alpha_view.competitions,
                classifications=alpha_view.classifications,
                themes=",".join(alpha_view.themes) if alpha_view.themes else None,
                team=",".join(alpha_view.team) if alpha_view.team else None,
            )

            return alpha
        except AttributeError as e:
            self.log.error(
                "åˆ›å»ºå› å­æ—¶å‘ç”Ÿé”™è¯¯",
                error=str(e),
                exc_info=True,
                module=__name__,
                emoji="âŒ",
            )
            raise AttributeError(f"å› å­æ•°æ®ç¼ºå°‘å¿…è¦å­—æ®µ: {e}") from e
        except Exception as e:
            self.log.error(
                "åˆ›å»ºå› å­æ—¶å‘ç”Ÿé”™è¯¯",
                error=str(e),
                exc_info=True,
                module=__name__,
                emoji="âŒ",
            )
            raise RuntimeError(f"åˆ›å»ºå› å­æ—¶å‘ç”Ÿé”™è¯¯: {e}") from e

    async def fetch_last_sync_time_range(
        self, client: WorldQuantClient
    ) -> Tuple[datetime, datetime]:

        await self.log.adebug(
            "è¿›å…¥ fetch_last_sync_time_range å‡½æ•°", client=str(client), emoji="ğŸ”"
        )

        try:
            async with get_db_session(Database.ALPHAS) as session:
                alpha_dal: AlphaDAL = DALFactory.create_dal(AlphaDAL, session)
                last_alpha: Optional[Alpha] = await alpha_dal.find_one_by(
                    order_by=Alpha.date_created.desc(),
                )

                start_time: datetime
                end_time: datetime = datetime.now()

                if last_alpha:
                    start_time = last_alpha.date_created
                    await self.log.adebug(
                        "æ‰¾åˆ°æœ€è¿‘çš„å› å­è®°å½•",
                        last_alpha_id=last_alpha.alpha_id,
                        last_alpha_date_created=last_alpha.date_created,
                        emoji="ğŸ“…",
                    )
                else:
                    query_params: SelfAlphaListQueryParams = SelfAlphaListQueryParams(
                        limit=1,
                        offset=0,
                        order="dateCreated",
                    )

                    alphas_data_result: SelfAlphaListView = (
                        await client.alpha_get_self_list(query=query_params)
                    )

                    if alphas_data_result.count > 0:
                        start_time = alphas_data_result.results[0].date_created
                        await self.log.adebug(
                            "ä» API è·å–æœ€è¿‘çš„å› å­è®°å½•",
                            api_result_count=alphas_data_result.count,
                            start_time=start_time,
                            emoji="ğŸŒ",
                        )
                    else:
                        start_time = datetime.now()
                        await self.log.awarning(
                            "æœªæ‰¾åˆ°ä»»ä½•å› å­è®°å½•ï¼Œä½¿ç”¨å½“å‰æ—¶é—´ä½œä¸ºå¼€å§‹æ—¶é—´",
                            start_time=start_time,
                            emoji="âš ï¸",
                        )
        except Exception as e:
            raise RuntimeError(f"è·å–åŒæ­¥æ—¶é—´èŒƒå›´æ—¶å‘ç”Ÿé”™è¯¯: {e}") from e

        await self.log.adebug(
            "é€€å‡º fetch_last_sync_time_range å‡½æ•°",
            start_time=start_time,
            end_time=end_time,
            emoji="âœ…",
        )
        return start_time, end_time

    async def process_alphas_page(
        self,
        alphas_results: List[AlphaView],
    ) -> List[Alpha]:
        uncommitted_alphas: List[Alpha] = []

        try:
            for alpha_view in alphas_results:
                if self.exit_event.is_set():
                    await self.log.awarning(
                        "æ£€æµ‹åˆ°é€€å‡ºäº‹ä»¶ï¼Œä¸­æ­¢å¤„ç†å› å­é¡µé¢", emoji="âš ï¸"
                    )
                    raise RuntimeError("é€€å‡ºäº‹ä»¶è§¦å‘ï¼Œåœæ­¢å¤„ç†å› å­é¡µé¢ã€‚")
                try:
                    alpha: Alpha = self.create_alpha(
                        alpha_view=alpha_view,
                    )

                    uncommitted_alphas.append(alpha)
                except Exception as e:
                    await self.log.aerror(
                        "å¤„ç†å•ä¸ªå› å­æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯",
                        alpha_id=alpha_view.id,
                        error=str(e),
                        exc_info=True,
                        emoji="âŒ",
                    )
                    raise
        except Exception as e:
            await self.log.aerror(
                "å•é¡µæ•°æ®å¤„ç†æ—¶å‘ç”Ÿé”™è¯¯",
                error=str(e),
                exc_info=True,
                emoji="âŒ",
            )
            raise RuntimeError(f"å•é¡µæ•°æ®å¤„ç†æ—¶å‘ç”Ÿé”™è¯¯: {e}") from e

        await self.log.adebug(
            "å•é¡µæ•°æ®å¤„ç†å®Œæˆ",
            count=len(uncommitted_alphas),
            emoji="âœ…",
        )
        return uncommitted_alphas

    async def process_alphas_for_time_range(
        self,
        client: WorldQuantClient,
        start_time: datetime,
        end_time: datetime,
        status: Optional[Status],
        parallel: int,
        dry_run: bool,
        max_count_per_loop: int = MAX_COUNT_IN_SINGLE_ALPHA_LIST_QUERY,
    ) -> Tuple[int, int, int]:

        fetched_alphas: int = 0
        inserted_alphas: int = 0
        updated_alphas: int = 0

        cur_time: datetime = start_time
        truncated_end_time: datetime = end_time

        try:
            while cur_time < end_time:
                if self.exit_event.is_set():
                    await self.log.awarning(
                        "æ£€æµ‹åˆ°é€€å‡ºäº‹ä»¶ï¼Œä¸­æ­¢å¤„ç†æ—¥æœŸèŒƒå›´",
                        start_time=start_time,
                        end_time=end_time,
                        cur_time=cur_time,
                        truncated_end_time=truncated_end_time,
                        emoji="âš ï¸",
                    )
                    break

                query_params: SelfAlphaListQueryParams = SelfAlphaListQueryParams(
                    limit=1,
                    date_created_gt=cur_time.isoformat(),
                    date_created_lt=truncated_end_time.isoformat(),
                    status_eq=status.value if status else None,
                )
                alphas_data_result: SelfAlphaListView
                alphas_data_result, _ = await client.alpha_get_self_list(
                    query=query_params
                )

                if alphas_data_result.count < min(
                    max_count_per_loop, MAX_COUNT_IN_SINGLE_ALPHA_LIST_QUERY
                ):
                    await self.log.ainfo(
                        "è·å–æ—¥æœŸèŒƒå›´æ•°æ®",
                        cur_time=cur_time,
                        truncated_end_time=truncated_end_time,
                        count=alphas_data_result.count,
                        emoji="ğŸ“…",
                    )
                    tasks: List[asyncio.Task] = []
                    page_size: int = 100
                    total_pages: int = (
                        alphas_data_result.count + page_size - 1
                    ) // page_size
                    pages_per_task: int = (total_pages + parallel - 1) // parallel

                    async with get_db_session(Database.ALPHAS) as session:
                        alpha_dal: AlphaDAL = AlphaDAL(session)

                        for i in range(parallel):
                            start_page: int = i * pages_per_task + 1
                            end_page: int = min((i + 1) * pages_per_task, total_pages)
                            if start_page > end_page:
                                break

                            task: asyncio.Task = asyncio.create_task(
                                self.process_alphas_pages(
                                    client=client,
                                    start_time=cur_time,
                                    end_time=truncated_end_time,
                                    status=status,
                                    start_page=start_page,
                                    end_page=end_page,
                                    page_size=page_size,
                                )
                            )

                            tasks.append(task)

                        results: List[Tuple[List[Alpha], int, int, int]] = (
                            await asyncio.gather(*tasks)
                        )

                        for (
                            uncommitted_alphas,
                            fetched,
                        ) in results:
                            if self.exit_event.is_set():
                                await self.log.awarning(
                                    "æ£€æµ‹åˆ°é€€å‡ºäº‹ä»¶ï¼Œä¸­æ­¢å¤„ç†æ—¥æœŸèŒƒå›´",
                                    start_time=start_time,
                                    end_time=end_time,
                                    cur_time=cur_time,
                                    truncated_end_time=truncated_end_time,
                                    emoji="âš ï¸",
                                )
                                break

                            fetched_alphas += fetched

                            if dry_run:
                                await self.log.ainfo(
                                    "å¹²è¿è¡Œæ¨¡å¼ï¼Œè·³è¿‡æ•°æ®å†™å…¥",
                                    start_time=start_time,
                                    end_time=end_time,
                                    cur_time=cur_time,
                                    truncated_end_time=truncated_end_time,
                                    count=len(uncommitted_alphas),
                                    emoji="ğŸ› ï¸",
                                )
                            else:
                                async with self._db_lock:
                                    await self.log.ainfo(
                                        "å†™å…¥å› å­æ•°æ®",
                                        start_time=start_time,
                                        end_time=end_time,
                                        cur_time=cur_time,
                                        truncated_end_time=truncated_end_time,
                                        count=len(uncommitted_alphas),
                                        emoji="ğŸ”„",
                                    )

                                    await alpha_dal.bulk_upsert_by_unique_key(
                                        uncommitted_alphas, unique_key="alpha_id"
                                    )
                                    await alpha_dal.session.commit()

                                    await self.log.ainfo(
                                        "å› å­æ•°æ®å†™å…¥å®Œæˆ",
                                        start_time=start_time,
                                        end_time=end_time,
                                        cur_time=cur_time,
                                        truncated_end_time=truncated_end_time,
                                        count=len(uncommitted_alphas),
                                        emoji="âœ…",
                                    )

                    cur_time = truncated_end_time
                    truncated_end_time = end_time
                    # è¿™é‡Œæ¸…ç†ä¸€ä¸‹èµ„æºï¼Œè¿›è¡Œåƒåœ¾å›æ”¶
                    del tasks
                    del alphas_data_result
                    del alpha_dal
                    gc.collect()

                else:
                    mid_time: datetime = cur_time + (truncated_end_time - cur_time) / 2
                    truncated_end_time = mid_time
                    await self.log.ainfo(
                        "æ•°æ®é‡è¶…è¿‡é™åˆ¶ï¼Œç¼©å°æ—¥æœŸèŒƒå›´",
                        start_time=start_time,
                        end_time=end_time,
                        cur_time=cur_time,
                        truncated_end_time=truncated_end_time,
                        emoji="âš ï¸",
                    )
        except Exception as e:
            await self.log.aerror(
                "å¤„ç†æ—¥æœŸèŒƒå›´å†…çš„å› å­æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯",
                start_time=start_time,
                end_time=end_time,
                error=str(e),
                exc_info=True,
                emoji="âŒ",
            )
            raise RuntimeError(f"å¤„ç†æ—¥æœŸèŒƒå›´å†…çš„å› å­æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {e}") from e

        return fetched_alphas, inserted_alphas, updated_alphas

    async def process_alphas_pages(
        self,
        client: WorldQuantClient,
        start_time: datetime,
        end_time: datetime,
        status: Optional[Status],
        start_page: int,
        end_page: int,
        page_size: int,
    ) -> Tuple[List[Alpha], int]:

        fetched_alphas: int = 0
        uncommited_alphas: List[Alpha] = []

        try:
            for page in range(start_page, end_page + 1):
                if self.exit_event.is_set():
                    await self.log.awarning(
                        "æ£€æµ‹åˆ°é€€å‡ºäº‹ä»¶ï¼Œä¸­æ­¢å¤„ç†å¤šé¡µæ•°æ®", emoji="âš ï¸"
                    )
                    raise RuntimeError("é€€å‡ºäº‹ä»¶è§¦å‘ï¼Œåœæ­¢å¤„ç†å¤šé¡µæ•°æ®ã€‚")
                query_params: SelfAlphaListQueryParams = SelfAlphaListQueryParams(
                    limit=page_size,
                    offset=(page - 1) * page_size,
                    date_created_gt=start_time.isoformat(),
                    date_created_lt=end_time.isoformat(),
                    order="dateCreated",
                    status_eq=status.value if status else None,
                )
                alphas_data_result: SelfAlphaListView
                alphas_data_result, _ = await client.alpha_get_self_list(
                    query=query_params
                )

                if not alphas_data_result.results:
                    break

                fetched_alphas += len(alphas_data_result.results)
                await self.log.ainfo(
                    "è·å–å¤šé¡µæ•°æ®",
                    start_time=start_time,
                    end_time=end_time,
                    page=page,
                    count=len(alphas_data_result.results),
                    emoji="ğŸ”",
                )
                alphas = await self.process_alphas_page(
                    alphas_data_result.results,
                )
                uncommited_alphas.extend(alphas)
        except Exception as e:
            await self.log.aerror(
                "å¤„ç†å¤šé¡µæ•°æ®æ—¶å‘ç”Ÿé”™è¯¯",
                start_time=start_time,
                end_time=end_time,
                error=str(e),
                exc_info=True,
                emoji="âŒ",
            )
            raise RuntimeError(f"å¤„ç†å¤šé¡µæ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {e}") from e

        return uncommited_alphas, fetched_alphas

    async def sync_alphas(
        self,
        start_time: Optional[datetime] = None,
        end_time: Optional[datetime] = None,
        status: Optional[Status] = None,
        increamental: bool = False,
        parallel: int = 1,
        dry_run: bool = False,
        max_count_per_loop: int = MAX_COUNT_IN_SINGLE_ALPHA_LIST_QUERY,
    ) -> None:

        if increamental:
            async with wq_client:
                sync_time_range: Tuple[datetime, datetime] = (
                    await self.fetch_last_sync_time_range(wq_client)
                )

                start_time = (
                    max(sync_time_range[0], start_time)
                    if start_time
                    else sync_time_range[0]
                )
                end_time = (
                    min(sync_time_range[1], end_time)
                    if end_time
                    else sync_time_range[1]
                )
        else:
            if start_time is None:
                start_time = datetime.now() - timedelta(days=1)
            if end_time is None:
                end_time = datetime.now()

        if start_time >= end_time:
            raise ValueError("start_time å¿…é¡»æ—©äº end_timeã€‚")

        if await competition_data_expire_check():
            await self.log.ainfo(
                "ç«èµ›æ•°æ®è¿‡æœŸï¼Œå‡†å¤‡åŒæ­¥",
                start_time=start_time,
                end_time=end_time,
                emoji="ğŸ› ï¸",
            )
            await sync_competition()
            await self.log.ainfo(
                "ç«èµ›æ•°æ®åŒæ­¥å®Œæˆ",
                start_time=start_time,
                end_time=end_time,
                emoji="âœ…",
            )

        self.setup_exit_signal_handler()

        await self.log.ainfo("å¼€å§‹åŒæ­¥å› å­", emoji="ğŸš€")

        async with wq_client:
            try:
                for i in range((end_time - start_time).days):
                    cur_start_time: datetime = start_time + timedelta(days=i)
                    cur_end_time: datetime = cur_start_time + timedelta(days=1)
                    cur_end_time = min(cur_end_time, end_time)

                    await self.log.ainfo(
                        "å¤„ç†æ—¶é—´èŒƒå›´",
                        start_time=cur_start_time,
                        end_time=cur_end_time,
                        emoji="ğŸ•’",
                    )

                    if self.exit_event.is_set():
                        await self.log.awarning(
                            "æ£€æµ‹åˆ°é€€å‡ºäº‹ä»¶ï¼Œä¸­æ­¢å¤„ç†æ—¶é—´èŒƒå›´",
                            start_time=cur_start_time,
                            end_time=cur_end_time,
                            emoji="âš ï¸",
                        )
                        break

                    fetched_alphas, inserted_alphas, updated_alphas = (
                        await self.process_alphas_for_time_range(
                            client=wq_client,
                            start_time=cur_start_time,
                            end_time=cur_end_time,
                            status=status,
                            parallel=parallel,
                            dry_run=dry_run,
                            max_count_per_loop=max_count_per_loop,
                        )
                    )
                await self.log.ainfo(
                    "å› å­åŒæ­¥å®Œæˆ",
                    fetched=fetched_alphas,
                    inserted=inserted_alphas,
                    updated=updated_alphas,
                    module=__name__,
                    emoji="âœ…",
                )
            except ValueError as ve:
                await self.log.aerror(
                    "å‚æ•°é”™è¯¯ï¼Œæ— æ³•åŒæ­¥å› å­",
                    error=str(ve),
                    start_time=start_time,
                    end_time=end_time,
                    module=__name__,
                    emoji="âŒ",
                )
                raise
            except RuntimeError as re:
                await self.log.aerror(
                    "è¿è¡Œæ—¶é”™è¯¯ï¼Œå› å­åŒæ­¥å¤±è´¥",
                    error=str(re),
                    exc_info=True,
                    module=__name__,
                    emoji="âŒ",
                )
                raise
            except Exception as e:
                await self.log.acritical(
                    "æœªçŸ¥é”™è¯¯ï¼Œå› å­åŒæ­¥ä¸­æ­¢",
                    error=str(e),
                    exc_info=True,
                    module=__name__,
                    emoji="ğŸ’¥",
                )
                raise
            finally:
                if self.exit_event.is_set():
                    await self.log.ainfo(
                        "å› å­åŒæ­¥è¢«ä¸­æ­¢",
                        module=__name__,
                        emoji="ğŸ›‘",
                    )
